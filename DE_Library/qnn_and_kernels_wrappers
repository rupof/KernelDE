import numpy as np
from squlearn.qnn import ODELoss



def get_differentials(f_alpha_tensor, x_span = None):

    if x_span is None: #Then, we are using a QNN
        loss_values = f_alpha_tensor #f_alpha_tensor is the loss_values dictionary
        x = loss_values["x"]
        f = loss_values["f"]
        dfdx = loss_values["dfdx"][:,0]
        try: 
            dfdxdx = loss_values["dfdxdx"][:,0,0]
            return x, f, dfdx, dfdxdx
        except:
            return x, f, dfdx, np.zeros_like(f)
    else: #Then, we are using a Kernel
        x = x_span
        f = f_alpha_tensor[0]
        dfdx = f_alpha_tensor[1]
        try: 
            dfdxdx = f_alpha_tensor[2]
        except:
            dfdxdx = np.zeros_like(f)
        return x, f, dfdx, dfdxdx



def create_QNN_loss(loss_functional):
    def QNN_loss(QNN_derivatives_values):
        """
        Defines the loss function for the ODE problem
        f_array is assumed to be [x, f, dfdx, dfdxdx]
        
        """
        return loss_functional(get_differentials(QNN_derivatives_values))
    return QNN_loss


def ODELoss_wrapper(ODE_functional, ODE_functional_gradient, initial_vec, eta = 1.0, boundary_handling = "pinned"):
    return ODELoss(create_QNN_loss(ODE_functional), ODE_functional_gradient, initial_vec, eta, boundary_handling)

