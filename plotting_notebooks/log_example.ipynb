{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from squlearn.encoding_circuit.encoding_circuit_derivatives import *\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "from solvers.MMR.kernel_solver import Solver\n",
    "from solvers.MMR.PQK_solver import PQK_solver\n",
    "from solvers.MMR.FQK_solver import FQK_solver\n",
    "from DE_Library.diferential_equation_functionals import *\n",
    "\n",
    "from utils.rbf_kernel_tools import *\n",
    "from circuits.circuits import *\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this notebook it is necessary to have installed my branch of squlearn installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_log_ode(f_alpha_tensor, x_span = None):\n",
    "    \"\"\"\n",
    "    0 = lamb * np.exp(f * k) - df/dx\n",
    "    f(0.001) = np.log(0.001)\n",
    "\n",
    "    solution: f(x) = np.log(x)\n",
    "    \"\"\"\n",
    "    if x_span is None: #Then, we are using a QNN\n",
    "        loss_values = f_alpha_tensor #f_alpha_tensor is the loss_values dictionary\n",
    "        x = loss_values[\"x\"]\n",
    "        f = loss_values[\"f\"]\n",
    "        dfdx = loss_values[\"dfdx\"][:,0]\n",
    "    else: #Then, we are using a Kernel\n",
    "        x = x_span\n",
    "        f = f_alpha_tensor[0]\n",
    "        dfdx = f_alpha_tensor[1]\n",
    "\n",
    "    lamb = 1\n",
    "    k = 1\n",
    "    return dfdx - np.exp(-f*k)*lamb \n",
    "\n",
    "def grad_loss_log_ode(loss_values, x_span = None):\n",
    "    \"\"\"\n",
    "    n = x_span.shape[0] number of points\n",
    "    m = x_span.shape[1] number of dimensions (typically m=1)\n",
    "\n",
    "    F[x, x_, x__] = F(x, x_, x__)\n",
    "\n",
    "    grad_F = (F(x, x_, x__)dx, F(x, x_, x__)dx_, F(x, x_, x__)dx__)\n",
    "\n",
    "    F = lamb * np.exp(f * k) - df/dx\n",
    "\n",
    "    grad_F = (-lamb*k, -1, 0)\n",
    "    \"\"\"\n",
    "    lamb = 1\n",
    "    k = 1\n",
    "    x, f, dfdx, dfdxdx = get_differentials(loss_values, x_span)\n",
    "\n",
    "    dFdf = lamb*k*np.exp(-f*k)\n",
    "    dFdfdx = 1\n",
    "    dFdfdxdx = 0\n",
    "\n",
    "    dfdp = loss_values[\"dfdp\"] # shape (n, p)\n",
    "    n_param = dfdp.shape[1]\n",
    "    \n",
    "    grad_envelope_list = np.zeros((3, x.shape[0], n_param)) # shape (3, n, p)\n",
    "    grad_envelope_list[0,:,:] = np.tile(dFdf, (n_param, 1)).T  \n",
    "    grad_envelope_list[1,:,:] = np.tile(dFdfdx, (n_param, 1)).T\n",
    "    grad_envelope_list[2,:,:] =  np.tile(dFdfdxdx, (n_param, 1)).T\n",
    "    return grad_envelope_list\n",
    "\n",
    "def derivatives_loss_log_ode(f_alpha_tensor, x_span = None):\n",
    "    \"\"\"\n",
    "    0 = lamb * np.exp(f * k) - df/dx\n",
    "    f(0.001) = np.log(0.001)\n",
    "\n",
    "    solution: f(x) = np.log(x)\n",
    "    \"\"\"\n",
    "    f = f_alpha_tensor[0]\n",
    "    lamb = 1\n",
    "    k = 1\n",
    "    return [np.exp(-f*k)*lamb]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0\n",
      "1.1514583145575512\n",
      "2.1170744197860083\n",
      "2.760094162506745\n",
      "3.024111195258129\n",
      "2.936848175541887\n",
      "2.5886603652691877\n",
      "2.09735913771174\n",
      "1.573817224059704\n",
      "1.0990943284995962\n",
      "0.7167359919622719\n",
      "0.437479050851241\n",
      "0.2503743243372308\n",
      "0.13453474835198898\n",
      "0.06794231400863966\n",
      "0.03227478393665685\n",
      "0.014430801707154026\n",
      "0.006076540484640026\n",
      "0.0024107689167119956\n",
      "0.0009014691913414004\n",
      "-1.1514583145575512\n",
      "-0.0\n",
      "1.1514583145575505\n",
      "2.1170744197860083\n",
      "2.760094162506745\n",
      "3.0241111952581288\n",
      "2.9368481755418876\n",
      "2.5886603652691877\n",
      "2.09735913771174\n",
      "1.5738172240597053\n",
      "1.0990943284995962\n",
      "0.7167359919622719\n",
      "0.4374790508512415\n",
      "0.2503743243372308\n",
      "0.13453474835198898\n",
      "0.06794231400863983\n",
      "0.03227478393665685\n",
      "0.014430801707154026\n",
      "0.006076540484640036\n",
      "0.0024107689167119956\n",
      "-2.1170744197860083\n",
      "-1.1514583145575505\n",
      "-0.0\n",
      "1.1514583145575512\n",
      "2.1170744197860087\n",
      "2.7600941625067454\n",
      "3.024111195258129\n",
      "2.9368481755418876\n",
      "2.5886603652691873\n",
      "2.097359137711741\n",
      "1.573817224059705\n",
      "1.0990943284995958\n",
      "0.7167359919622724\n",
      "0.437479050851241\n",
      "0.2503743243372308\n",
      "0.13453474835198934\n",
      "0.06794231400863966\n",
      "0.03227478393665685\n",
      "0.01443080170715405\n",
      "0.006076540484640026\n",
      "-2.760094162506745\n",
      "-2.1170744197860083\n",
      "-1.1514583145575512\n",
      "-0.0\n",
      "1.1514583145575512\n",
      "2.117074419786009\n",
      "2.760094162506745\n",
      "3.024111195258129\n",
      "2.936848175541887\n",
      "2.5886603652691877\n",
      "2.09735913771174\n",
      "1.573817224059704\n",
      "1.0990943284995962\n",
      "0.7167359919622719\n",
      "0.437479050851241\n",
      "0.2503743243372308\n",
      "0.13453474835198898\n",
      "0.06794231400863966\n",
      "0.03227478393665685\n",
      "0.014430801707154026\n",
      "-3.024111195258129\n",
      "-2.760094162506745\n",
      "-2.1170744197860087\n",
      "-1.1514583145575512\n",
      "-0.0\n",
      "1.1514583145575519\n",
      "2.117074419786008\n",
      "2.760094162506745\n",
      "3.0241111952581288\n",
      "2.9368481755418876\n",
      "2.5886603652691877\n",
      "2.09735913771174\n",
      "1.5738172240597053\n",
      "1.0990943284995962\n",
      "0.7167359919622719\n",
      "0.4374790508512415\n",
      "0.2503743243372308\n",
      "0.13453474835198898\n",
      "0.06794231400863983\n",
      "0.03227478393665685\n",
      "-2.936848175541887\n",
      "-3.0241111952581288\n",
      "-2.7600941625067454\n",
      "-2.117074419786009\n",
      "-1.1514583145575519\n",
      "-0.0\n",
      "1.1514583145575494\n",
      "2.117074419786008\n",
      "2.760094162506745\n",
      "3.0241111952581288\n",
      "2.9368481755418876\n",
      "2.5886603652691877\n",
      "2.097359137711741\n",
      "1.5738172240597053\n",
      "1.0990943284995962\n",
      "0.7167359919622727\n",
      "0.4374790508512415\n",
      "0.2503743243372308\n",
      "0.13453474835198934\n",
      "0.06794231400863983\n",
      "-2.5886603652691877\n",
      "-2.9368481755418876\n",
      "-3.024111195258129\n",
      "-2.760094162506745\n",
      "-2.117074419786008\n",
      "-1.1514583145575494\n",
      "-0.0\n",
      "1.1514583145575519\n",
      "2.1170744197860096\n",
      "2.760094162506745\n",
      "3.0241111952581288\n",
      "2.936848175541887\n",
      "2.5886603652691877\n",
      "2.09735913771174\n",
      "1.573817224059704\n",
      "1.0990943284995962\n",
      "0.7167359919622719\n",
      "0.437479050851241\n",
      "0.2503743243372308\n",
      "0.13453474835198898\n",
      "-2.09735913771174\n",
      "-2.5886603652691877\n",
      "-2.9368481755418876\n",
      "-3.024111195258129\n",
      "-2.760094162506745\n",
      "-2.117074419786008\n",
      "-1.1514583145575519\n",
      "-0.0\n",
      "1.1514583145575519\n",
      "2.117074419786008\n",
      "2.760094162506745\n",
      "3.0241111952581288\n",
      "2.9368481755418876\n",
      "2.5886603652691877\n",
      "2.09735913771174\n",
      "1.5738172240597053\n",
      "1.0990943284995962\n",
      "0.7167359919622719\n",
      "0.4374790508512415\n",
      "0.2503743243372308\n",
      "-1.573817224059704\n",
      "-2.09735913771174\n",
      "-2.5886603652691873\n",
      "-2.936848175541887\n",
      "-3.0241111952581288\n",
      "-2.760094162506745\n",
      "-2.1170744197860096\n",
      "-1.1514583145575519\n",
      "-0.0\n",
      "1.1514583145575494\n",
      "2.117074419786008\n",
      "2.760094162506745\n",
      "3.0241111952581288\n",
      "2.9368481755418876\n",
      "2.5886603652691877\n",
      "2.097359137711741\n",
      "1.5738172240597053\n",
      "1.0990943284995962\n",
      "0.7167359919622727\n",
      "0.4374790508512415\n",
      "-1.0990943284995962\n",
      "-1.5738172240597053\n",
      "-2.097359137711741\n",
      "-2.5886603652691877\n",
      "-2.9368481755418876\n",
      "-3.0241111952581288\n",
      "-2.760094162506745\n",
      "-2.117074419786008\n",
      "-1.1514583145575494\n",
      "-0.0\n",
      "1.1514583145575519\n",
      "2.1170744197860096\n",
      "2.760094162506745\n",
      "3.0241111952581288\n",
      "2.936848175541887\n",
      "2.5886603652691877\n",
      "2.09735913771174\n",
      "1.573817224059704\n",
      "1.0990943284995962\n",
      "0.7167359919622719\n",
      "-0.7167359919622719\n",
      "-1.0990943284995962\n",
      "-1.573817224059705\n",
      "-2.09735913771174\n",
      "-2.5886603652691877\n",
      "-2.9368481755418876\n",
      "-3.0241111952581288\n",
      "-2.760094162506745\n",
      "-2.117074419786008\n",
      "-1.1514583145575519\n",
      "-0.0\n",
      "1.1514583145575519\n",
      "2.117074419786008\n",
      "2.760094162506745\n",
      "3.0241111952581288\n",
      "2.9368481755418876\n",
      "2.5886603652691877\n",
      "2.09735913771174\n",
      "1.5738172240597053\n",
      "1.0990943284995962\n",
      "-0.437479050851241\n",
      "-0.7167359919622719\n",
      "-1.0990943284995958\n",
      "-1.573817224059704\n",
      "-2.09735913771174\n",
      "-2.5886603652691877\n",
      "-2.936848175541887\n",
      "-3.0241111952581288\n",
      "-2.760094162506745\n",
      "-2.1170744197860096\n",
      "-1.1514583145575519\n",
      "-0.0\n",
      "1.1514583145575494\n",
      "2.117074419786008\n",
      "2.760094162506745\n",
      "3.0241111952581288\n",
      "2.9368481755418876\n",
      "2.5886603652691877\n",
      "2.097359137711741\n",
      "1.5738172240597053\n",
      "-0.2503743243372308\n",
      "-0.4374790508512415\n",
      "-0.7167359919622724\n",
      "-1.0990943284995962\n",
      "-1.5738172240597053\n",
      "-2.097359137711741\n",
      "-2.5886603652691877\n",
      "-2.9368481755418876\n",
      "-3.0241111952581288\n",
      "-2.760094162506745\n",
      "-2.117074419786008\n",
      "-1.1514583145575494\n",
      "-0.0\n",
      "1.1514583145575519\n",
      "2.1170744197860096\n",
      "2.760094162506745\n",
      "3.0241111952581288\n",
      "2.936848175541887\n",
      "2.5886603652691877\n",
      "2.09735913771174\n",
      "-0.13453474835198898\n",
      "-0.2503743243372308\n",
      "-0.437479050851241\n",
      "-0.7167359919622719\n",
      "-1.0990943284995962\n",
      "-1.5738172240597053\n",
      "-2.09735913771174\n",
      "-2.5886603652691877\n",
      "-2.9368481755418876\n",
      "-3.0241111952581288\n",
      "-2.760094162506745\n",
      "-2.117074419786008\n",
      "-1.1514583145575519\n",
      "-0.0\n",
      "1.1514583145575519\n",
      "2.117074419786008\n",
      "2.760094162506745\n",
      "3.0241111952581288\n",
      "2.9368481755418876\n",
      "2.5886603652691877\n",
      "-0.06794231400863966\n",
      "-0.13453474835198898\n",
      "-0.2503743243372308\n",
      "-0.437479050851241\n",
      "-0.7167359919622719\n",
      "-1.0990943284995962\n",
      "-1.573817224059704\n",
      "-2.09735913771174\n",
      "-2.5886603652691877\n",
      "-2.936848175541887\n",
      "-3.0241111952581288\n",
      "-2.760094162506745\n",
      "-2.1170744197860096\n",
      "-1.1514583145575519\n",
      "-0.0\n",
      "1.1514583145575494\n",
      "2.117074419786008\n",
      "2.760094162506745\n",
      "3.0241111952581288\n",
      "2.9368481755418876\n",
      "-0.03227478393665685\n",
      "-0.06794231400863983\n",
      "-0.13453474835198934\n",
      "-0.2503743243372308\n",
      "-0.4374790508512415\n",
      "-0.7167359919622727\n",
      "-1.0990943284995962\n",
      "-1.5738172240597053\n",
      "-2.097359137711741\n",
      "-2.5886603652691877\n",
      "-2.9368481755418876\n",
      "-3.0241111952581288\n",
      "-2.760094162506745\n",
      "-2.117074419786008\n",
      "-1.1514583145575494\n",
      "-0.0\n",
      "1.1514583145575519\n",
      "2.1170744197860096\n",
      "2.760094162506745\n",
      "3.0241111952581288\n",
      "-0.014430801707154026\n",
      "-0.03227478393665685\n",
      "-0.06794231400863966\n",
      "-0.13453474835198898\n",
      "-0.2503743243372308\n",
      "-0.4374790508512415\n",
      "-0.7167359919622719\n",
      "-1.0990943284995962\n",
      "-1.5738172240597053\n",
      "-2.09735913771174\n",
      "-2.5886603652691877\n",
      "-2.9368481755418876\n",
      "-3.0241111952581288\n",
      "-2.760094162506745\n",
      "-2.117074419786008\n",
      "-1.1514583145575519\n",
      "-0.0\n",
      "1.1514583145575519\n",
      "2.117074419786008\n",
      "2.760094162506745\n",
      "-0.006076540484640026\n",
      "-0.014430801707154026\n",
      "-0.03227478393665685\n",
      "-0.06794231400863966\n",
      "-0.13453474835198898\n",
      "-0.2503743243372308\n",
      "-0.437479050851241\n",
      "-0.7167359919622719\n",
      "-1.0990943284995962\n",
      "-1.573817224059704\n",
      "-2.09735913771174\n",
      "-2.5886603652691877\n",
      "-2.936848175541887\n",
      "-3.0241111952581288\n",
      "-2.760094162506745\n",
      "-2.1170744197860096\n",
      "-1.1514583145575519\n",
      "-0.0\n",
      "1.1514583145575494\n",
      "2.117074419786008\n",
      "-0.0024107689167119956\n",
      "-0.006076540484640036\n",
      "-0.01443080170715405\n",
      "-0.03227478393665685\n",
      "-0.06794231400863983\n",
      "-0.13453474835198934\n",
      "-0.2503743243372308\n",
      "-0.4374790508512415\n",
      "-0.7167359919622727\n",
      "-1.0990943284995962\n",
      "-1.5738172240597053\n",
      "-2.097359137711741\n",
      "-2.5886603652691877\n",
      "-2.9368481755418876\n",
      "-3.0241111952581288\n",
      "-2.760094162506745\n",
      "-2.117074419786008\n",
      "-1.1514583145575494\n",
      "-0.0\n",
      "1.1514583145575519\n",
      "-0.0009014691913414004\n",
      "-0.0024107689167119956\n",
      "-0.006076540484640026\n",
      "-0.014430801707154026\n",
      "-0.03227478393665685\n",
      "-0.06794231400863983\n",
      "-0.13453474835198898\n",
      "-0.2503743243372308\n",
      "-0.4374790508512415\n",
      "-0.7167359919622719\n",
      "-1.0990943284995962\n",
      "-1.5738172240597053\n",
      "-2.09735913771174\n",
      "-2.5886603652691877\n",
      "-2.9368481755418876\n",
      "-3.0241111952581288\n",
      "-2.760094162506745\n",
      "-2.117074419786008\n",
      "-1.1514583145575519\n",
      "-0.0\n",
      "3\n",
      "Initial loss:  3402.0213386285377\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.069807\n",
      "         Iterations: 144\n",
      "         Function evaluations: 5138\n",
      "         Gradient evaluations: 233\n",
      "shapes\n",
      "output_f_gramm_matrix (20,)\n",
      "output_dfdx_gramm_matrix (20, 1)\n",
      "-0.0\n",
      "-0.33879350242846623\n",
      "-0.38002898608064595\n",
      "-0.1998247503194974\n",
      "-0.05627571201053093\n",
      "-0.00876787738415074\n",
      "-0.0007710338437960196\n",
      "-3.931765577190836e-05\n",
      "-1.2102432575721703e-06\n",
      "-2.3764378960478993e-08\n",
      "-3.1939545549632214e-10\n",
      "-3.1971237903880124e-12\n",
      "-2.6252085894407196e-14\n",
      "-1.9663021451008707e-16\n",
      "-1.5037910574806555e-18\n",
      "-1.3187430835814058e-20\n",
      "-1.4888158712849557e-22\n",
      "-2.420118957891821e-24\n",
      "-6.288765479233368e-26\n",
      "-2.869583325101464e-27\n",
      "0.33879350242846623\n",
      "-0.0\n",
      "-0.3493215455663069\n",
      "-0.36894203096510053\n",
      "-0.1782951562592222\n",
      "-0.04558639775909031\n",
      "-0.006454779274417413\n",
      "-0.0005237263748520983\n",
      "-2.5377208047103435e-05\n",
      "-7.751106142068988e-07\n",
      "-1.597514683579485e-08\n",
      "-2.4107633250644323e-10\n",
      "-2.9250817930349374e-12\n",
      "-3.163649834946036e-14\n",
      "-3.40400036198506e-16\n",
      "-4.080402439698549e-18\n",
      "-6.101869088862144e-20\n",
      "-1.2701078157179207e-21\n",
      "-4.0769550222729376e-23\n",
      "-2.2128471527543234e-24\n",
      "0.38002898608064595\n",
      "0.3493215455663069\n",
      "-0.0\n",
      "-0.35725661932150937\n",
      "-0.35897931102634334\n",
      "-0.1624829275607811\n",
      "-0.03880747283744767\n",
      "-0.005190939391845108\n",
      "-0.0004080801107987032\n",
      "-1.9920808757667925e-05\n",
      "-6.455345133109344e-07\n",
      "-1.5031767047008172e-08\n",
      "-2.7541473434123557e-10\n",
      "-4.388718933251401e-12\n",
      "-6.767710812758468e-14\n",
      "-1.1277286551613117e-15\n",
      "-2.2676885008601767e-17\n",
      "-6.124547939689931e-19\n",
      "-2.4559528400120487e-20\n",
      "-1.6002960021626134e-21\n",
      "0.1998247503194974\n",
      "0.36894203096510053\n",
      "0.35725661932150937\n",
      "-0.0\n",
      "-0.36293892943481776\n",
      "-0.35109030685881515\n",
      "-0.15198805273221444\n",
      "-0.03496654754838157\n",
      "-0.004600945888011419\n",
      "-0.000368327392304159\n",
      "-1.9195090056310274e-05\n",
      "-7.039255805303223e-07\n",
      "-1.9842932918999738e-08\n",
      "-4.739025385609988e-10\n",
      "-1.0638459415348174e-11\n",
      "-2.499324174508823e-13\n",
      "-6.8436003451760416e-15\n",
      "-2.424727002470413e-16\n",
      "-1.2260831552702955e-17\n",
      "-9.664685625589337e-19\n",
      "0.05627571201053093\n",
      "0.1782951562592222\n",
      "0.35897931102634334\n",
      "0.36293892943481776\n",
      "-0.0\n",
      "-0.36665016634413333\n",
      "-0.3458921201085067\n",
      "-0.14643817613107196\n",
      "-0.03349860093590526\n",
      "-0.004516587254828428\n",
      "-0.000386639831749082\n",
      "-2.273568019611924e-05\n",
      "-1.001779107305204e-06\n",
      "-3.636994135666785e-08\n",
      "-1.203768766930174e-09\n",
      "-4.0327977924505236e-11\n",
      "-1.5188615786928315e-12\n",
      "-7.121604109626102e-14\n",
      "-4.574665344007923e-15\n",
      "-4.3887063003043944e-16\n",
      "0.00876787738415074\n",
      "0.04558639775909031\n",
      "0.1624829275607811\n",
      "0.35109030685881515\n",
      "0.36665016634413333\n",
      "-0.0\n",
      "-0.36859447464416784\n",
      "-0.3437367079629947\n",
      "-0.14560307685850699\n",
      "-0.034185896406043734\n",
      "-0.004914293981238813\n",
      "-0.0004711307192824286\n",
      "-3.2889379738622555e-05\n",
      "-1.8360707259497275e-06\n",
      "-9.049220735648817e-08\n",
      "-4.360677771414863e-09\n",
      "-2.276058534811215e-10\n",
      "-1.4214435393817765e-11\n",
      "-1.1662477748721208e-12\n",
      "-1.3676885384357077e-13\n",
      "0.0007710338437960196\n",
      "0.006454779274417413\n",
      "0.03880747283744767\n",
      "0.15198805273221444\n",
      "0.3458921201085067\n",
      "0.36859447464416784\n",
      "-0.0\n",
      "-0.3688859700825319\n",
      "-0.3447584540769642\n",
      "-0.1494461582285968\n",
      "-0.037130472722759836\n",
      "-0.005906282528984459\n",
      "-0.0006612803226257989\n",
      "-5.729324371541578e-05\n",
      "-4.23600977028783e-06\n",
      "-2.954059421321262e-07\n",
      "-2.147657148480119e-08\n",
      "-1.7940193004922605e-09\n",
      "-1.8865557630320282e-10\n",
      "-2.7119581004727382e-11\n",
      "3.931765577190836e-05\n",
      "0.0005237263748520983\n",
      "0.005190939391845108\n",
      "0.03496654754838157\n",
      "0.14643817613107196\n",
      "0.3437367079629947\n",
      "0.3688859700825319\n",
      "-0.0\n",
      "-0.36754221543763405\n",
      "-0.34889446927560425\n",
      "-0.15813161138804505\n",
      "-0.042767335024612836\n",
      "-0.007782531126199262\n",
      "-0.0010550291838942428\n",
      "-0.0001176522555299286\n",
      "-1.19187621654762e-05\n",
      "-1.2103044474507226e-06\n",
      "-1.355089087808547e-07\n",
      "-1.8292101079695214e-08\n",
      "-3.2269587001442353e-09\n",
      "1.2102432575721703e-06\n",
      "2.5377208047103435e-05\n",
      "0.0004080801107987032\n",
      "0.004600945888011419\n",
      "0.03349860093590526\n",
      "0.14560307685850699\n",
      "0.3447584540769642\n",
      "0.36754221543763405\n",
      "-0.0\n",
      "-0.36448324458827125\n",
      "-0.3558749312005801\n",
      "-0.1719901686580021\n",
      "-0.05191474522939101\n",
      "-0.011116543802514\n",
      "-0.0018783141035005255\n",
      "-0.0002769999231926166\n",
      "-3.93193665128118e-05\n",
      "-5.9011236990192546e-06\n",
      "-1.022296060163122e-06\n",
      "-2.2123613981198176e-07\n",
      "2.3764378960478993e-08\n",
      "7.751106142068988e-07\n",
      "1.9920808757667925e-05\n",
      "0.000368327392304159\n",
      "0.004516587254828428\n",
      "0.034185896406043734\n",
      "0.1494461582285968\n",
      "0.34889446927560425\n",
      "0.36448324458827125\n",
      "-0.0\n",
      "-0.35953606659880927\n",
      "-0.36518470476480325\n",
      "-0.19143025253824564\n",
      "-0.06584228764747299\n",
      "-0.016960438956415035\n",
      "-0.0036467495201556077\n",
      "-0.0007231869286679119\n",
      "-0.00014527046492496726\n",
      "-3.223818952619459e-05\n",
      "-8.543249393445251e-06\n",
      "3.1939545549632214e-10\n",
      "1.597514683579485e-08\n",
      "6.455345133109344e-07\n",
      "1.9195090056310274e-05\n",
      "0.000386639831749082\n",
      "0.004914293981238813\n",
      "0.037130472722759836\n",
      "0.15813161138804505\n",
      "0.3558749312005801\n",
      "0.35953606659880927\n",
      "-0.0\n",
      "-0.3524449495857807\n",
      "-0.3760018924199514\n",
      "-0.21676719067412628\n",
      "-0.08630496368924485\n",
      "-0.027150360334012306\n",
      "-0.007516450690143433\n",
      "-0.002015829065406022\n",
      "-0.0005713107604484724\n",
      "-0.0001848446000848145\n",
      "3.1971237903880124e-12\n",
      "2.4107633250644323e-10\n",
      "1.5031767047008172e-08\n",
      "7.039255805303223e-07\n",
      "2.273568019611924e-05\n",
      "0.0004711307192824286\n",
      "0.005906282528984459\n",
      "0.042767335024612836\n",
      "0.1719901686580021\n",
      "0.36518470476480325\n",
      "0.3524449495857807\n",
      "-0.0\n",
      "-0.3428880364957058\n",
      "-0.3871251289365694\n",
      "-0.24793623601162698\n",
      "-0.11543168637954987\n",
      "-0.044681690326926274\n",
      "-0.015962095210814983\n",
      "-0.005756431012471826\n",
      "-0.0022652827120507465\n",
      "2.6252085894407196e-14\n",
      "2.9250817930349374e-12\n",
      "2.7541473434123557e-10\n",
      "1.9842932918999738e-08\n",
      "1.001779107305204e-06\n",
      "3.2889379738622555e-05\n",
      "0.0006612803226257989\n",
      "0.007782531126199262\n",
      "0.05191474522939101\n",
      "0.19143025253824564\n",
      "0.3760018924199514\n",
      "0.3428880364957058\n",
      "-0.0\n",
      "-0.33050084994749446\n",
      "-0.39690986916590004\n",
      "-0.2840662982119323\n",
      "-0.1552731307524965\n",
      "-0.07391873500317242\n",
      "-0.033817905392012494\n",
      "-0.01612214838260732\n",
      "1.9663021451008707e-16\n",
      "3.163649834946036e-14\n",
      "4.388718933251401e-12\n",
      "4.739025385609988e-10\n",
      "3.636994135666785e-08\n",
      "1.8360707259497275e-06\n",
      "5.729324371541578e-05\n",
      "0.0010550291838942428\n",
      "0.011116543802514\n",
      "0.06584228764747299\n",
      "0.21676719067412628\n",
      "0.3871251289365694\n",
      "0.33050084994749446\n",
      "-0.0\n",
      "-0.31490689483395995\n",
      "-0.4032436070973959\n",
      "-0.3229367281718233\n",
      "-0.20675549474538413\n",
      "-0.12000782071266945\n",
      "-0.06910355950660914\n",
      "1.5037910574806555e-18\n",
      "3.40400036198506e-16\n",
      "6.767710812758468e-14\n",
      "1.0638459415348174e-11\n",
      "1.203768766930174e-09\n",
      "9.049220735648817e-08\n",
      "4.23600977028783e-06\n",
      "0.0001176522555299286\n",
      "0.0018783141035005255\n",
      "0.016960438956415035\n",
      "0.08630496368924485\n",
      "0.24793623601162698\n",
      "0.39690986916590004\n",
      "0.31490689483395995\n",
      "-0.0\n",
      "-0.2957548102252125\n",
      "-0.40359765392616254\n",
      "-0.3604325471801732\n",
      "-0.2678821534805224\n",
      "-0.1864091727075203\n",
      "1.3187430835814058e-20\n",
      "4.080402439698549e-18\n",
      "1.1277286551613117e-15\n",
      "2.499324174508823e-13\n",
      "4.0327977924505236e-11\n",
      "4.360677771414863e-09\n",
      "2.954059421321262e-07\n",
      "1.19187621654762e-05\n",
      "0.0002769999231926166\n",
      "0.0036467495201556077\n",
      "0.027150360334012306\n",
      "0.11543168637954987\n",
      "0.2840662982119323\n",
      "0.4032436070973959\n",
      "0.2957548102252125\n",
      "-0.0\n",
      "-0.27276038417671017\n",
      "-0.39519315727006576\n",
      "-0.39024492466458083\n",
      "-0.33146475813976195\n",
      "1.4888158712849557e-22\n",
      "6.101869088862144e-20\n",
      "2.2676885008601767e-17\n",
      "6.8436003451760416e-15\n",
      "1.5188615786928315e-12\n",
      "2.276058534811215e-10\n",
      "2.147657148480119e-08\n",
      "1.2103044474507226e-06\n",
      "3.93193665128118e-05\n",
      "0.0007231869286679119\n",
      "0.007516450690143433\n",
      "0.044681690326926274\n",
      "0.1552731307524965\n",
      "0.3229367281718233\n",
      "0.40359765392616254\n",
      "0.27276038417671017\n",
      "-0.0\n",
      "-0.24575036679970147\n",
      "-0.37530477036183685\n",
      "-0.4041754444640813\n",
      "2.420118957891821e-24\n",
      "1.2701078157179207e-21\n",
      "6.124547939689931e-19\n",
      "2.424727002470413e-16\n",
      "7.121604109626102e-14\n",
      "1.4214435393817765e-11\n",
      "1.7940193004922605e-09\n",
      "1.355089087808547e-07\n",
      "5.9011236990192546e-06\n",
      "0.00014527046492496726\n",
      "0.002015829065406022\n",
      "0.015962095210814983\n",
      "0.07391873500317242\n",
      "0.20675549474538413\n",
      "0.3604325471801732\n",
      "0.39519315727006576\n",
      "0.24575036679970147\n",
      "-0.0\n",
      "-0.21470366203487645\n",
      "-0.34169241770241615\n",
      "6.288765479233368e-26\n",
      "4.0769550222729376e-23\n",
      "2.4559528400120487e-20\n",
      "1.2260831552702955e-17\n",
      "4.574665344007923e-15\n",
      "1.1662477748721208e-12\n",
      "1.8865557630320282e-10\n",
      "1.8292101079695214e-08\n",
      "1.022296060163122e-06\n",
      "3.223818952619459e-05\n",
      "0.0005713107604484724\n",
      "0.005756431012471826\n",
      "0.033817905392012494\n",
      "0.12000782071266945\n",
      "0.2678821534805224\n",
      "0.39024492466458083\n",
      "0.37530477036183685\n",
      "0.21470366203487645\n",
      "-0.0\n",
      "-0.17978450762348247\n",
      "2.869583325101464e-27\n",
      "2.2128471527543234e-24\n",
      "1.6002960021626134e-21\n",
      "9.664685625589337e-19\n",
      "4.3887063003043944e-16\n",
      "1.3676885384357077e-13\n",
      "2.7119581004727382e-11\n",
      "3.2269587001442353e-09\n",
      "2.2123613981198176e-07\n",
      "8.543249393445251e-06\n",
      "0.0001848446000848145\n",
      "0.0022652827120507465\n",
      "0.01612214838260732\n",
      "0.06910355950660914\n",
      "0.1864091727075203\n",
      "0.33146475813976195\n",
      "0.4041754444640813\n",
      "0.34169241770241615\n",
      "0.17978450762348247\n",
      "-0.0\n",
      "shapes\n",
      "output_f_gramm_matrix (20, 20)\n",
      "output_dfdx_gramm_matrix (20, 20)\n",
      "output_dfdxdx_gramm_matrix (20, 20)\n",
      "K_f (20, 20)\n",
      "K_dfdx (20, 20)\n",
      "K_dfdxdx (20, 20)\n",
      "3\n",
      "Initial loss:  1125.7818946426728\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.011975\n",
      "         Iterations: 95\n",
      "         Function evaluations: 2938\n",
      "         Gradient evaluations: 133\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'L_functional_1ODE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 46\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#mse_list[idx] = np.mean((f_PQK - f_odeint)**2)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \n\u001b[0;32m     35\u001b[0m \n\u001b[0;32m     36\u001b[0m \n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# = solution_PQK[1]\u001b[39;00m\n\u001b[0;32m     41\u001b[0m FQK_solver_test \u001b[38;5;241m=\u001b[39m FQK_solver({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_circuit\u001b[39m\u001b[38;5;124m\"\u001b[39m: HardwareEfficientEmbeddingCircuit_qiskit, \n\u001b[0;32m     42\u001b[0m                               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_qubits\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m7\u001b[39m, \u001b[38;5;66;03m#6\u001b[39;00m\n\u001b[0;32m     43\u001b[0m                               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     44\u001b[0m                               },\n\u001b[0;32m     45\u001b[0m                               Executor(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpennylane\u001b[39m\u001b[38;5;124m\"\u001b[39m),)\n\u001b[1;32m---> 46\u001b[0m solution_FQK, kernel_listFQK \u001b[38;5;241m=\u001b[39m FQK_solver_test\u001b[38;5;241m.\u001b[39msolver(x_line, f_initial, \u001b[43mL_functional_1ODE\u001b[49m)\n\u001b[0;32m     47\u001b[0m f_FQK, optimal_alpha_FQK \u001b[38;5;241m=\u001b[39m solution_FQK[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     50\u001b[0m f_odeint \u001b[38;5;241m=\u001b[39m odeint(derivatives_loss_log_ode, f_initial, x_line[:])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'L_functional_1ODE' is not defined"
     ]
    }
   ],
   "source": [
    "x_line = np.linspace(0.1, 1, 20)\n",
    "f_initial = [np.log(x_line[0])]\n",
    "\n",
    "\n",
    "#Classical Solver\n",
    "#RBF\n",
    "RBF_kernel_list = [rbf_kernel_manual(x_line, x_line, sigma = 0.2), analytical_derivative_rbf_kernel(x_line, x_line, sigma = 0.2), analytical_derivative_rbf_kernel_2(x_line, x_line, sigma = 0.2)]\n",
    "Solver_test = Solver(RBF_kernel_list, regularization_parameter=1)\n",
    "solution_RBF, _ = Solver_test.solver(x_line, f_initial, L_functional = loss_log_ode)\n",
    "f_RBF, optimal_alpha_RBF = solution_RBF[0], solution_RBF[1] #fix bug here\n",
    "\n",
    "\n",
    "#PQK\n",
    "sigma_list = np.linspace(0.1, 1, 70)\n",
    "mse_list = np.zeros_like(sigma_list)\n",
    "#for idx, sigma in enumerate(sigma_list):\n",
    "sigma = 1.5\n",
    "\n",
    "\n",
    "PQK_solver_test = PQK_solver({\"encoding_circuit\": Separable_rx_qiskit, \n",
    "                            \"num_qubits\": 8,\n",
    "                            \"num_layers\": 2,\n",
    "                            },\n",
    "                            Executor(\"pennylane\"), \n",
    "                            envelope={\"function\": rbf_kernel_manual, \n",
    "                                        \"derivative_function\": analytical_derivative_rbf_kernel, \n",
    "                                        \"second_derivative_function\": analytical_derivative_rbf_kernel_2,\n",
    "                                        \"sigma\": sigma})\n",
    "\n",
    "\n",
    "solution_PQK, kernel_list_PQK = PQK_solver_test.solver(x_line, f_initial, L_functional = loss_log_ode)\n",
    "f_PQK, optimal_alpha_PQK = solution_PQK[0] ##fix bug here\n",
    "#mse_list[idx] = np.mean((f_PQK - f_odeint)**2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # = solution_PQK[1]\n",
    "\n",
    "\n",
    "FQK_solver_test = FQK_solver({\"encoding_circuit\": HardwareEfficientEmbeddingCircuit_qiskit, \n",
    "                              \"num_qubits\": 7, #6\n",
    "                              \"num_layers\": 2,\n",
    "                              },\n",
    "                              Executor(\"pennylane\"),)\n",
    "solution_FQK, kernel_listFQK = FQK_solver_test.solver(x_line, f_initial, loss_log_ode)\n",
    "f_FQK, optimal_alpha_FQK = solution_FQK[0]\n",
    "\n",
    "\n",
    "f_odeint = odeint(derivatives_loss_log_ode, f_initial, x_line[:])\n",
    "\n",
    "\n",
    "\n",
    "x_span_plot = x_line.reshape(-1, 1)\n",
    "plt.plot(x_span_plot, f_odeint, \"-*\",label=\"odeint\")\n",
    "plt.plot(x_span_plot, f_RBF, \"x\", label=\"RBF\")\n",
    "plt.plot(x_span_plot, f_PQK, label=\"PQK\")\n",
    "#plt.plot(x_span_plot, f_FQK, \"-x\",label=\"FQK\")\n",
    "plt.plot(x_span_plot, np.log(x_span_plot), label=\"log(x)\")\n",
    "#plt.ylim(-3, 3)\n",
    "\n",
    "\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.xlabel(\"x\")\n",
    "\n",
    "str_PQK_info = PQK_solver_test.print_plotting_relevant_info()\n",
    "plt.text(1.1, 0.3, str_PQK_info, \n",
    "         bbox=dict(facecolor=f\"C{1}\", alpha=0.5))\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PQK: Separable_rx_qiskit encoding_circuit: Separable_rx_qiskit num_qubits: 8 num_layers: 2 rbf_kernel_manual envelope: rbf_kernel_manual sigma: 1.5 '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PQK_solver_test.print_plotting_relevant_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ini_for_qnn_log = np.array([-0.8668401 ,  0.62015684, -2.15667028, -0.95454592, -2.89136728,\n",
    "       -1.92620405, -2.42505116, -0.73693033,  0.15005287,  0.11193568,\n",
    "       -0.05050098,  0.1663773 , -1.60720058,  2.65320097, -2.67566268,\n",
    "        1.73276216, -0.50043699, -0.0168493 , -2.00266291, -1.08206438,\n",
    "        1.86698375,  3.38838397, -1.28013607,  0.40042087,  2.48657952,\n",
    "        1.84133399, -2.57681948, -2.25447227, -1.48390435,  2.34203517,\n",
    "       -3.05758795,  0.07006922,  2.83425198,  0.51826963,  0.283995  ,\n",
    "       -1.27784187,  1.79961911,  1.75086033, -2.58554971,  2.22307143,\n",
    "        3.21987049,  1.26645828, -1.5382721 ,  0.61663127, -2.49837747,\n",
    "        0.67758954,  1.76342976,  0.28877661, -0.44080463, -2.08639276,\n",
    "       -3.71336053,  0.42384569, -1.3393165 ,  0.12151889,  0.26585592,\n",
    "       -3.43308924,  0.83359602, -2.13203627,  0.78660411,  0.28519979,\n",
    "       -2.34090764, -0.64527869,  0.51750895, -0.32511686, -3.35527718,\n",
    "        0.22554386,  1.28212405,  0.09355113,  1.97205487,  0.54384149,\n",
    "        1.71538417, -2.27781413, -2.78838724,  1.93139642, -1.72878695,\n",
    "       -2.10264181,  2.15244049, -0.95651545,  1.62222138,  1.41998766])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from squlearn.observables import SummedPaulis\n",
    "from squlearn.qnn import QNNRegressor, ODELoss\n",
    "from squlearn.qnn.lowlevel_qnn import LowLevelQNN\n",
    "from squlearn.optimizers import SLSQP, Adam\n",
    "from squlearn.qnn.loss import *\n",
    "from squlearn.qnn.training import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_qubits = 8\n",
    "num_features = 1\n",
    "num_layers = 5\n",
    "circuit = YZ_CX_EncodingCircuit(num_qubits, num_features, num_layers)\n",
    "executor = Executor(\"pennylane\")\n",
    "\n",
    "Observables = SummedPaulis(num_qubits, include_identity=False)                                                      \n",
    "param_obs = Observables.generate_initial_parameters(seed=1)\n",
    "param_ini = params_ini_for_qnn_log\n",
    "#param_ini = circuit.generate_initial_parameters(seed=1)\n",
    "\n",
    "\n",
    "\n",
    "slsqp = SLSQP(options={\"maxiter\": 150, \"ftol\": 0.05})\n",
    "adam = Adam(options={\"maxiter\": 350, \"tol\": 0.00009})\n",
    "\n",
    "initial_value = np.array([np.log(0.01)])\n",
    "loss_ODE = ODELoss(loss_log_ode, grad_loss_log_ode, initial_vec = initial_value, eta=1)\n",
    "\n",
    "\n",
    "clf = QNNRegressor(\n",
    "    circuit,\n",
    "    Observables,\n",
    "    executor,\n",
    "    loss_ODE,\n",
    "    adam,\n",
    "    param_ini,\n",
    "    param_obs,\n",
    "    opt_param_op = False, #Parametrized Observables not benchmarked yet\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit:   0%|          | 0/350 [00:00<?, ?it/s]PARAM [-0.8668401   0.62015684 -2.15667028 -0.95454592 -2.89136728 -1.92620405\n",
      " -2.42505116 -0.73693033  0.15005287  0.11193568 -0.05050098  0.1663773\n",
      " -1.60720058  2.65320097 -2.67566268  1.73276216 -0.50043699 -0.0168493\n",
      " -2.00266291 -1.08206438  1.86698375  3.38838397 -1.28013607  0.40042087\n",
      "  2.48657952  1.84133399 -2.57681948 -2.25447227 -1.48390435  2.34203517\n",
      " -3.05758795  0.07006922  2.83425198  0.51826963  0.283995   -1.27784187\n",
      "  1.79961911  1.75086033 -2.58554971  2.22307143  3.21987049  1.26645828\n",
      " -1.5382721   0.61663127 -2.49837747  0.67758954  1.76342976  0.28877661\n",
      " -0.44080463 -2.08639276 -3.71336053  0.42384569 -1.3393165   0.12151889\n",
      "  0.26585592 -3.43308924  0.83359602 -2.13203627  0.78660411  0.28519979\n",
      " -2.34090764 -0.64527869  0.51750895 -0.32511686 -3.35527718  0.22554386\n",
      "  1.28212405  0.09355113  1.97205487  0.54384149  1.71538417 -2.27781413\n",
      " -2.78838724  1.93139642 -1.72878695 -2.10264181  2.15244049 -0.95651545\n",
      "  1.62222138  1.41998766]\n",
      "INPUT [0.1        0.14736842 0.19473684 0.24210526 0.28947368 0.33684211\n",
      " 0.38421053 0.43157895 0.47894737 0.52631579 0.57368421 0.62105263\n",
      " 0.66842105 0.71578947 0.76315789 0.81052632 0.85789474 0.90526316\n",
      " 0.95263158 1.        ]\n",
      "LOSS 17.01616073214415\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m y_ODE \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((x_line\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m----> 2\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_line\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_ODE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m f_QNN \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(x_line)\n",
      "File \u001b[1;32m~\\Desktop\\Qiskit\\squlearnRF\\src\\squlearn\\qnn\\qnnr.py:240\u001b[0m, in \u001b[0;36mQNNRegressor._fit\u001b[1;34m(self, X, y, weights)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpbar\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pbar \u001b[38;5;241m=\u001b[39m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_total_iterations, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstdout)\n\u001b[1;32m--> 240\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpbar\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pbar\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\Desktop\\Qiskit\\squlearnRF\\src\\squlearn\\qnn\\qnnr.py:222\u001b[0m, in \u001b[0;36mQNNRegressor.partial_fit\u001b[1;34m(self, X, y, weights)\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param_op \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m    210\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qnn,\n\u001b[0;32m    211\u001b[0m             X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    220\u001b[0m         )\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 222\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_qnn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_param\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_param_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshot_control\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_fitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\Qiskit\\squlearnRF\\src\\squlearn\\qnn\\training.py:403\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(qnn, input_values, ground_truth, param_ini, param_op_ini, loss, optimizer, shot_control, weights, opt_param_op, print_numerical_grad)\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m--> 403\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ini\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    406\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[1;32m~\\Desktop\\Qiskit\\squlearnRF\\src\\squlearn\\optimizers\\adam.py:129\u001b[0m, in \u001b[0;36mAdam.minimize\u001b[1;34m(self, fun, x0, grad, bounds)\u001b[0m\n\u001b[0;32m    125\u001b[0m     fval \u001b[38;5;241m=\u001b[39m fun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Calculate the gradient and average it over the last num_average gradients\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# (1 is default: no averaging)\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_deque\u001b[38;5;241m.\u001b[39mappend(\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    130\u001b[0m gradient \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_deque, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    132\u001b[0m x_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx, grad\u001b[38;5;241m=\u001b[39mgradient)\n",
      "File \u001b[1;32m~\\Desktop\\Qiskit\\squlearnRF\\src\\squlearn\\qnn\\training.py:350\u001b[0m, in \u001b[0;36mtrain.<locals>._grad\u001b[1;34m(theta)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss variance necessary for ShotsFromRSTD shot control\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 350\u001b[0m grad_values \u001b[38;5;241m=\u001b[39m \u001b[43mqnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_op_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_args_tuple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[0;32m    352\u001b[0m     loss\u001b[38;5;241m.\u001b[39mgradient(\n\u001b[0;32m    353\u001b[0m         grad_values,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    360\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    361\u001b[0m )\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m print_numerical_grad:\n",
      "File \u001b[1;32m~\\Desktop\\Qiskit\\squlearnRF\\src\\squlearn\\qnn\\lowlevel_qnn_pennylane.py:389\u001b[0m, in \u001b[0;36mLowLevelQNNPennyLane.evaluate\u001b[1;34m(self, x, param, param_obs, *values)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    382\u001b[0m \n\u001b[0;32m    383\u001b[0m     \u001b[38;5;66;03m# Direct evaluation of the QNN\u001b[39;00m\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (todo_class\u001b[38;5;241m.\u001b[39mreturn_grad_x \u001b[38;5;129;01mand\u001b[39;00m todo_class\u001b[38;5;241m.\u001b[39morder \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    385\u001b[0m         todo_class\u001b[38;5;241m.\u001b[39morder \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor\u001b[38;5;241m.\u001b[39mshots \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    386\u001b[0m     ):  \u001b[38;5;66;03m# TODO: Should be removed if PennyLane bug 4462 is fixed\u001b[39;00m\n\u001b[0;32m    387\u001b[0m         \u001b[38;5;66;03m# evaluate every single x, param, param_op combination separately\u001b[39;00m\n\u001b[0;32m    388\u001b[0m         \u001b[38;5;66;03m# faster evaluation for higher-order derivatives w.r.t. x\u001b[39;00m\n\u001b[1;32m--> 389\u001b[0m         output \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    390\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate_todo_single_x(\n\u001b[0;32m    391\u001b[0m                 todo_class, x_inp_, param_inp_, param_obs_inp_\n\u001b[0;32m    392\u001b[0m             )\n\u001b[0;32m    393\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m x_inp_ \u001b[38;5;129;01min\u001b[39;00m x_inp\n\u001b[0;32m    394\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m param_inp_ \u001b[38;5;129;01min\u001b[39;00m param_inp\n\u001b[0;32m    395\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m param_obs_inp_ \u001b[38;5;129;01min\u001b[39;00m param_obs_inp\n\u001b[0;32m    396\u001b[0m         ]\n\u001b[0;32m    397\u001b[0m         output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(output)\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    400\u001b[0m         \u001b[38;5;66;03m# evaluate only param, param_op combination separately and all x together\u001b[39;00m\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;66;03m# Faster evaluation for lower-order derivatives\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\Qiskit\\squlearnRF\\src\\squlearn\\qnn\\lowlevel_qnn_pennylane.py:390\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    382\u001b[0m \n\u001b[0;32m    383\u001b[0m     \u001b[38;5;66;03m# Direct evaluation of the QNN\u001b[39;00m\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (todo_class\u001b[38;5;241m.\u001b[39mreturn_grad_x \u001b[38;5;129;01mand\u001b[39;00m todo_class\u001b[38;5;241m.\u001b[39morder \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    385\u001b[0m         todo_class\u001b[38;5;241m.\u001b[39morder \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor\u001b[38;5;241m.\u001b[39mshots \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    386\u001b[0m     ):  \u001b[38;5;66;03m# TODO: Should be removed if PennyLane bug 4462 is fixed\u001b[39;00m\n\u001b[0;32m    387\u001b[0m         \u001b[38;5;66;03m# evaluate every single x, param, param_op combination separately\u001b[39;00m\n\u001b[0;32m    388\u001b[0m         \u001b[38;5;66;03m# faster evaluation for higher-order derivatives w.r.t. x\u001b[39;00m\n\u001b[0;32m    389\u001b[0m         output \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 390\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_todo_single_x\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtodo_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_inp_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_inp_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_obs_inp_\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m x_inp_ \u001b[38;5;129;01min\u001b[39;00m x_inp\n\u001b[0;32m    394\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m param_inp_ \u001b[38;5;129;01min\u001b[39;00m param_inp\n\u001b[0;32m    395\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m param_obs_inp_ \u001b[38;5;129;01min\u001b[39;00m param_obs_inp\n\u001b[0;32m    396\u001b[0m         ]\n\u001b[0;32m    397\u001b[0m         output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(output)\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    400\u001b[0m         \u001b[38;5;66;03m# evaluate only param, param_op combination separately and all x together\u001b[39;00m\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;66;03m# Faster evaluation for lower-order derivatives\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\Qiskit\\squlearnRF\\src\\squlearn\\qnn\\lowlevel_qnn_pennylane.py:538\u001b[0m, in \u001b[0;36mLowLevelQNNPennyLane._evaluate_todo_single_x\u001b[1;34m(self, todo_class, x, param, param_obs)\u001b[0m\n\u001b[0;32m    536\u001b[0m     hash_value \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39mhash \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(todo_class\u001b[38;5;241m.\u001b[39margnum)\n\u001b[0;32m    537\u001b[0m     deriv\u001b[38;5;241m.\u001b[39mhash \u001b[38;5;241m=\u001b[39m hash_value\n\u001b[1;32m--> 538\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpennylane_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mderiv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43meval_tuple\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;66;03m# Convert back to numpy array\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mreal_if_close(np\u001b[38;5;241m.\u001b[39marray(value))\n",
      "File \u001b[1;32m~\\Desktop\\Qiskit\\squlearnRF\\src\\squlearn\\util\\executor.py:483\u001b[0m, in \u001b[0;36mExecutor.pennylane_execute\u001b[1;34m(self, pennylane_circuit, *args, **kwargs)\u001b[0m\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pennylane_circuit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# Call function for cached execution\u001b[39;00m\n\u001b[1;32m--> 483\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pennylane_execute_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecute_circuit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Qiskit\\squlearnRF\\src\\squlearn\\util\\executor.py:577\u001b[0m, in \u001b[0;36mExecutor._pennylane_execute_cached\u001b[1;34m(self, function, hash_value)\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# Execute the circuit todo: implement restart\u001b[39;00m\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    573\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecutor start execution of pennylane circuit with hash value: \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    574\u001b[0m             hash_value\n\u001b[0;32m    575\u001b[0m         )\n\u001b[0;32m    576\u001b[0m     )\n\u001b[1;32m--> 577\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution of pennylane circuit successful\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Desktop\\Qiskit\\squlearnRF\\src\\squlearn\\util\\executor.py:480\u001b[0m, in \u001b[0;36mExecutor.pennylane_execute.<locals>.execute_circuit\u001b[1;34m()\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_circuit\u001b[39m():\n\u001b[1;32m--> 480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pennylane_circuit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pennylane\\_grad.py:330\u001b[0m, in \u001b[0;36mjacobian.<locals>._jacobian_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _argnum:\n\u001b[0;32m    325\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to differentiate a function with no trainable parameters. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf this is unintended, please add trainable parameters via the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m attribute or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margnum\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    329\u001b[0m     )\n\u001b[1;32m--> 330\u001b[0m jac \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_jacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_argnum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jac[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m unpack \u001b[38;5;28;01melse\u001b[39;00m jac\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pennylane\\_grad.py:330\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _argnum:\n\u001b[0;32m    325\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to differentiate a function with no trainable parameters. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf this is unintended, please add trainable parameters via the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m attribute or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margnum\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    329\u001b[0m     )\n\u001b[1;32m--> 330\u001b[0m jac \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(_jacobian(func, arg)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m _argnum)\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jac[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m unpack \u001b[38;5;28;01melse\u001b[39;00m jac\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autograd\\wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(args[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnum)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unary_operator(unary_f, x, \u001b[38;5;241m*\u001b[39mnary_op_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnary_op_kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autograd\\differential_operators.py:60\u001b[0m, in \u001b[0;36mjacobian\u001b[1;34m(fun, x)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;129m@unary_to_nary\u001b[39m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjacobian\u001b[39m(fun, x):\n\u001b[0;32m     52\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m    Returns a function which computes the Jacobian of `fun` with respect to\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m    positional argument number `argnum`, which must be a scalar or array. Unlike\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m    (out1, out2, ...) then the Jacobian has shape (out1, out2, ..., in1, in2, ...).\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     vjp, ans \u001b[38;5;241m=\u001b[39m \u001b[43m_make_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     ans_vspace \u001b[38;5;241m=\u001b[39m vspace(ans)\n\u001b[0;32m     62\u001b[0m     jacobian_shape \u001b[38;5;241m=\u001b[39m ans_vspace\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m+\u001b[39m vspace(x)\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autograd\\core.py:10\u001b[0m, in \u001b[0;36mmake_vjp\u001b[1;34m(fun, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_vjp\u001b[39m(fun, x):\n\u001b[0;32m      9\u001b[0m     start_node \u001b[38;5;241m=\u001b[39m VJPNode\u001b[38;5;241m.\u001b[39mnew_root()\n\u001b[1;32m---> 10\u001b[0m     end_value, end_node \u001b[38;5;241m=\u001b[39m  \u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end_node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(g): \u001b[38;5;28;01mreturn\u001b[39;00m vspace(x)\u001b[38;5;241m.\u001b[39mzeros()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autograd\\tracer.py:10\u001b[0m, in \u001b[0;36mtrace\u001b[1;34m(start_node, fun, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace_stack\u001b[38;5;241m.\u001b[39mnew_trace() \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[0;32m      9\u001b[0m     start_box \u001b[38;5;241m=\u001b[39m new_box(x, t, start_node)\n\u001b[1;32m---> 10\u001b[0m     end_box \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_box\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isbox(end_box) \u001b[38;5;129;01mand\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_trace \u001b[38;5;241m==\u001b[39m start_box\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_value, end_box\u001b[38;5;241m.\u001b[39m_node\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autograd\\wrap_util.py:15\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f.<locals>.unary_f\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     subargs \u001b[38;5;241m=\u001b[39m subvals(args, \u001b[38;5;28mzip\u001b[39m(argnum, x))\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;241m*\u001b[39msubargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pennylane\\_grad.py:330\u001b[0m, in \u001b[0;36mjacobian.<locals>._jacobian_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _argnum:\n\u001b[0;32m    325\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to differentiate a function with no trainable parameters. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf this is unintended, please add trainable parameters via the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m attribute or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margnum\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    329\u001b[0m     )\n\u001b[1;32m--> 330\u001b[0m jac \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_jacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_argnum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jac[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m unpack \u001b[38;5;28;01melse\u001b[39;00m jac\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pennylane\\_grad.py:330\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _argnum:\n\u001b[0;32m    325\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to differentiate a function with no trainable parameters. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf this is unintended, please add trainable parameters via the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m attribute or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margnum\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    329\u001b[0m     )\n\u001b[1;32m--> 330\u001b[0m jac \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(_jacobian(func, arg)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m _argnum)\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jac[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m unpack \u001b[38;5;28;01melse\u001b[39;00m jac\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autograd\\wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(args[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnum)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unary_operator(unary_f, x, \u001b[38;5;241m*\u001b[39mnary_op_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnary_op_kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autograd\\differential_operators.py:64\u001b[0m, in \u001b[0;36mjacobian\u001b[1;34m(fun, x)\u001b[0m\n\u001b[0;32m     62\u001b[0m jacobian_shape \u001b[38;5;241m=\u001b[39m ans_vspace\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m+\u001b[39m vspace(x)\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     63\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(vjp, ans_vspace\u001b[38;5;241m.\u001b[39mstandard_basis())\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mreshape(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m)\u001b[49m, jacobian_shape)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autograd\\numpy\\numpy_wrapper.py:88\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(arrays, axis)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack\u001b[39m(arrays, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# this code is basically copied from numpy/core/shape_base.py's stack\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# we need it here because we want to re-implement stack in terms of the\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m# primitives defined in this file\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [array(arr) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arrays:\n\u001b[0;32m     90\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneed at least one array to stack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autograd\\numpy\\numpy_wrapper.py:88\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack\u001b[39m(arrays, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# this code is basically copied from numpy/core/shape_base.py's stack\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# we need it here because we want to re-implement stack in terms of the\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m# primitives defined in this file\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [array(arr) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arrays:\n\u001b[0;32m     90\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneed at least one array to stack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autograd\\core.py:14\u001b[0m, in \u001b[0;36mmake_vjp.<locals>.vjp\u001b[1;34m(g)\u001b[0m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(g): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_node\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autograd\\core.py:23\u001b[0m, in \u001b[0;36mbackward_pass\u001b[1;34m(g, end_node)\u001b[0m\n\u001b[0;32m     21\u001b[0m     ingrads \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mvjp(outgrad[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m parent, ingrad \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39mparents, ingrads):\n\u001b[1;32m---> 23\u001b[0m         outgrads[parent] \u001b[38;5;241m=\u001b[39m \u001b[43madd_outgrads\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutgrads\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mingrad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outgrad[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autograd\\core.py:176\u001b[0m, in \u001b[0;36madd_outgrads\u001b[1;34m(prev_g_flagged, g)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sparse:\n\u001b[1;32m--> 176\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msparse_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvspace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m g, \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autograd\\tracer.py:44\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m parents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(box\u001b[38;5;241m.\u001b[39m_node \u001b[38;5;28;01mfor\u001b[39;00m _     , box \u001b[38;5;129;01min\u001b[39;00m boxed_args)\n\u001b[0;32m     43\u001b[0m argnums \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(argnum    \u001b[38;5;28;01mfor\u001b[39;00m argnum, _   \u001b[38;5;129;01min\u001b[39;00m boxed_args)\n\u001b[1;32m---> 44\u001b[0m ans \u001b[38;5;241m=\u001b[39m f_wrapped(\u001b[38;5;241m*\u001b[39margvals, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     45\u001b[0m node \u001b[38;5;241m=\u001b[39m node_constructor(ans, f_wrapped, argvals, kwargs, argnums, parents)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_box(ans, trace, node)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autograd\\tracer.py:48\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_box(ans, trace, node)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f_raw(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autograd\\core.py:186\u001b[0m, in \u001b[0;36msparse_add\u001b[1;34m(vs, x_prev, x_new)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;129m@primitive\u001b[39m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msparse_add\u001b[39m(vs, x_prev, x_new):\n\u001b[0;32m    185\u001b[0m     x_prev \u001b[38;5;241m=\u001b[39m x_prev \u001b[38;5;28;01mif\u001b[39;00m x_prev \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m vs\u001b[38;5;241m.\u001b[39mzeros()\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx_new\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmut_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_prev\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autograd\\numpy\\numpy_vjps.py:698\u001b[0m, in \u001b[0;36muntake.<locals>.mut_add\u001b[1;34m(A)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmut_add\u001b[39m(A):\n\u001b[1;32m--> 698\u001b[0m     \u001b[43monp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m A\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_ODE = np.zeros((x_line.shape[0]))\n",
    "clf._fit(x_line, y_ODE,  weights=None)\n",
    "f_QNN = clf.predict(x_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<solvers.MMR.PQK_solver.PQK_solver at 0x2049578e500>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PQK_solver_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_info_text(df_row):\n",
    "    df = df_row\n",
    "    text = \"\"\n",
    "    if df[\"method\"] == \"PQK\":\n",
    "        text += f\"L: {df['CI_num_layers']}, \"\n",
    "        text += \"$n_{qubits}$\" +f\": {df['CI_num_qubits']}, \"\n",
    "        text += f\"$\\gamma$:  {np.round(df['gamma'], 3)}, \"\n",
    "        text += f\"fmap: {df['CI_encoding_circuit_label'][:-7]}\"\n",
    "    elif df[\"method\"] == \"FQK\":\n",
    "        text += f\"L: {df['CI_num_layers']}, \"\n",
    "        text += \"$n_{qubits}$\" +f\": {df['CI_num_qubits']}, \"\n",
    "        text += f\"fmap: {df['CI_encoding_circuit_label'][:-7]}\"\n",
    "    elif df[\"method\"] == \"classical_RBF\":\n",
    "        text += f\"$\\gamma$: {np.round(df['gamma'], 3)}\"\n",
    "    return text\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_PQK_info = str(get_relevant_info_text(results_PQK[results_PQK[\"g_name\"] == \"g_paper\"].iloc[0]))\n",
    "plt.text(1.1, 0.5, str_PQK_info, \n",
    "         bbox=dict(facecolor=f\"C{0}\", alpha=0.5))\n",
    "str_FQK_info = str(get_relevant_info_text(results_FQK[results_FQK[\"g_name\"] == \"g_paper\"].iloc[0]))\n",
    "plt.text(1.1, 0.3, str_FQK_info, \n",
    "         bbox=dict(facecolor=f\"C{1}\", alpha=0.5))\n",
    "str_RBF_info = str(get_relevant_info_text(results_RBF[results_RBF[\"g_name\"] == \"g_paper\"].iloc[0]))\n",
    "plt.text(1.1, 0.1, str_RBF_info, \n",
    "         bbox=dict(facecolor=f\"C{2}\", alpha=0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20498809cc0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_span_plot, f_odeint, \"-*\",label=\"odeint\")\n",
    "plt.plot(x_span_plot, f_RBF, \"x\", label=\"RBF\")\n",
    "plt.plot(x_span_plot, f_PQK, label=\"PQK\")\n",
    "plt.plot(x_span_plot, f_QNN, \"o\", label=\"QNN\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
